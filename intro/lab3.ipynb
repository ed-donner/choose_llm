{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e6f24ec",
   "metadata": {},
   "source": [
    "# Lab 3\n",
    "\n",
    "## Groq versus Cerebras for fast inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b3506e-b46f-44f0-ba9b-6b002835d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from litellm import completion\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfae0a99-0235-4256-9874-1b5e718b6fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a39ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"\"\"\n",
    "Write a python function that uses the Sieve of Eratosthenes to find the first 100 primes whose digits sum to 10.\n",
    "Explain your approach but don't try to predict the answer.\n",
    "\"\"\"\n",
    "messages = [{\"role\": \"user\", \"content\": message}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27667987",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def speed_test(model, provider=None):\n",
    "    start = datetime.now()\n",
    "    if provider:\n",
    "        stream = completion(model=model, messages=messages, stream=True, extra_body={\n",
    "        \"provider\": {\n",
    "            \"order\": [provider]\n",
    "        }\n",
    "    })\n",
    "    else:\n",
    "        stream = completion(model=model, messages=messages, stream=True)\n",
    "    handle = display(Markdown(\"\"), display_id=True)\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        update_display(Markdown(result), display_id=handle.display_id)\n",
    "    end = datetime.now()\n",
    "    print(f\"Time taken: {(end - start).total_seconds()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd6297b",
   "metadata": {},
   "source": [
    "# Speed Battle\n",
    "\n",
    "## First up: Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215b05d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_test(\"groq/openai/gpt-oss-120b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53efa7b",
   "metadata": {},
   "source": [
    "## And now the challenger: Cerebras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dad26c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_test(\"openrouter/openai/gpt-oss-120b\", provider=\"cerebras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedbbd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
