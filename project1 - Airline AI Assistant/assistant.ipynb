{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70629249-1ff7-4638-8d44-5f07e67a071b",
   "metadata": {},
   "source": [
    "# Project 1 - Airline AI Assistant\n",
    "\n",
    "For this first project, we'll work on one of the very common use cases for Gen AI: a chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac6d332-5739-4e66-9871-3bfeb42dfc94",
   "metadata": {},
   "source": [
    "## Setting up your keys\n",
    "\n",
    "If you haven't done so already, you'll need to create API keys from OpenAI.\n",
    "\n",
    "For OpenAI, visit https://openai.com/api/  \n",
    "\n",
    "When you get your API keys, you need to set them as environment variables.\n",
    "\n",
    "EITHER (recommended) create a file called .env in this project root directory, and set your keys there:\n",
    "```\n",
    "OPENAI_API_KEY=xxxx\n",
    "````\n",
    "\n",
    "OR enter the keys directly in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d259d97-5061-43af-a641-3088c4df8106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5f0ff9-75ff-4d81-81c7-c36a05511151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "# Used for printing in color\n",
    "\n",
    "BLUE = \"\\033[34m\"\n",
    "RESET = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716f24dc-ed56-4ac4-8b68-00554a186945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our chatbot we will select GPT-4o-mini due to the price efficiency\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748dd333-328c-4b3e-be58-a71b396fdc92",
   "metadata": {},
   "source": [
    "## Our first Assistant conversation\n",
    "\n",
    "We can call the API with a conversation - a list of dictionaries representing each interaction:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"essential instructions here, including tone\"},\n",
    "    {\"role\": \"user\", \"content\": \"a question from the user\"},\n",
    "    {\"role\": \"assistant\": \"content\": \"a response\"},\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc7248-ba02-4e00-9479-9435ec76721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant for an Airline called FlightAI. \"\n",
    "system_message += \"Give short, courteous answers, no more than 1 sentence. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e10bd8f-98c0-4379-b69b-f1607ef257d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [{\"role\": \"system\", \"content\": system_message}]\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    message = input(\"Your message:\")\n",
    "    if message == \"stop\":\n",
    "        print(BLUE + \"Bye\" + RESET)\n",
    "        done = True\n",
    "    else:\n",
    "        conversation.append({\"role\": \"user\", \"content\": message})\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=conversation)\n",
    "        reply = response.choices[0].message.content\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": reply})\n",
    "        print(BLUE + reply + RESET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7beff0-eb67-4892-aa39-351d98f96d40",
   "metadata": {},
   "source": [
    "## Amazing! As simple as that.\n",
    "\n",
    "### Isn't it great to see the way the LLM keeps the context of the conversation?\n",
    "\n",
    "### It's important to realize that this is an illusion - we pass in the entire conversation with every call.\n",
    "\n",
    "Try playing with the System Prompt to vary the tone.  \n",
    "\n",
    "And now we wrap this in a simple chat() function,  \n",
    "and then we use the shockingly simple Gradio platform to bring up a Chatbot UI.\n",
    "\n",
    "First, the chat function, which takes the current message and the history of prior messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a26c37-36a3-47d9-91ad-56c7c2489a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd056244-2326-4828-93d1-4af979715017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And look how complicated it is to launch a User Interface, with the fabulous gradio platform\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba266303-707d-4e06-882a-7323bdd812db",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Another incredibly powerful feature is the ability to give the LLM some \"tools\"  \n",
    "Or functions it can call in order to do its job better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdcf2af-24ca-4d9d-a722-a6f62b623275",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"sydney\": \"$2999\"}\n",
    "\n",
    "def get_ticket_price(destination_city):\n",
    "    print(f\"Tool get_ticket_price called for {destination_city}\")\n",
    "    city = destination_city.lower()\n",
    "    return ticket_prices.get(city, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463c8e7-fe1d-48ac-8245-9e01fd2980bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ticket_price(\"Sydney\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66e6861-1b58-4779-b525-5925a9aea3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19637da3-3621-485c-9abe-34417afe6586",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\"type\": \"function\", \"function\": price_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e017bd3-6fee-42d3-aeea-e007bcaeed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "\n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        response, city = handle_tool_call(message)\n",
    "        messages.append(message)\n",
    "        messages.append(response)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78894d94-4be0-4bdf-8763-16e5fafadd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to write that function handle_tool_call:\n",
    "\n",
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "    city = arguments.get('destination_city')\n",
    "    price = get_ticket_price(city)\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\"destination_city\": city,\"price\": price}),\n",
    "        \"tool_call_id\": message.tool_calls[0].id\n",
    "    }\n",
    "    return response, city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e862272-cc53-48bd-aad7-fb4a982afc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7174aff0-b2d1-41cb-a93f-c371c8bbad76",
   "metadata": {},
   "source": [
    "## Agentization (in a simple way)\n",
    "\n",
    "Giving our Assistant the ability to interact with a Tool could be considered adding an Agentic design pattern to our solution. LLMs being able to use tools is one of the Hallmarks of Agentic AI.\n",
    "\n",
    "Another example is having multiple AIs collaborate to solve the problem. Let's add another AI to the mix!\n",
    "\n",
    "Let's pick a fun one: adding multi-modality.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec51107b-50ac-4d6c-aa80-205694c3bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "def artist_agent(city):\n",
    "    image_response = openai.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt=f\"An image representing a vacation in {city}, showing tourist spots and everything unique about {city}, in a vibrant pop-art style\",\n",
    "            size=\"1024x1024\",\n",
    "            n=1,\n",
    "            response_format=\"b64_json\",\n",
    "        )\n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311244a0-9175-429f-9635-4023de705808",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = artist_agent(\"New York\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d76e9be-70e5-47d7-bdc8-a484630c19a0",
   "metadata": {},
   "source": [
    "## Bringing it all together in a mini Agent Framework\n",
    "\n",
    "Finally we bring together our Assistant, Tool and Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c832443b-8051-426f-a787-05f6f65ec84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    image = None\n",
    "    \n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        response, city = handle_tool_call(message)\n",
    "        messages.append(message)\n",
    "        messages.append(response)\n",
    "        image = artist_agent(city)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "        \n",
    "    reply = response.choices[0].message.content\n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "    return history, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bdcb30-dfab-4a83-958c-702522f388f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More involved Gradio code as we're not using the preset Chat interface!\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "        image_output = gr.Image(height=500)\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "\n",
    "    def do_entry(message, history):\n",
    "        history += [{\"role\":\"user\", \"content\":message}]\n",
    "        return \"\", history\n",
    "\n",
    "    entry.submit(do_entry, inputs=[entry, chatbot], outputs=[entry, chatbot]).then(\n",
    "        chat, inputs=chatbot, outputs=[chatbot, image_output]\n",
    "    )\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b79b8fb-6c38-4034-b154-0a3f79e0572b",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You just created a multi-modal AI Assistant with tools and agents\n",
    "\n",
    "Further exercises:\n",
    "\n",
    "1. Swap OpenAI for Claude to experience the changes in style\n",
    "2. Add another agent to the mix: have the chat respond in audio as well as text\n",
    "3. Add another tool to simulate booking the flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754f6ff2-2f4e-4890-8ff6-df3077155b62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
